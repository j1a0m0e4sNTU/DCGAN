        
ID: test 
 infomation: test beta value for Adam 
 Generator: g_tutorial 
 Discriminator: d_tutorial 
 Learning rate: 0.002 
 Epoch number: 10 
 Batch size: 64 
 =======================

Generator(
  (model): Sequential(
    (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace)
    (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace)
    (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace)
    (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): ReLU(inplace)
    (12): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (13): Tanh()
  )
)
Discriminator(
  (model): Sequential(
    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): LeakyReLU(negative_slope=0.2, inplace)
    (3): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): LeakyReLU(negative_slope=0.2, inplace)
    (6): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): LeakyReLU(negative_slope=0.2, inplace)
    (9): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (10): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): LeakyReLU(negative_slope=0.2, inplace)
    (12): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)
    (13): Sigmoid()
  )
)
 Epoch  0 Step 100 | G loss : 0.13115401566028595 | D loss (real) :  0.0011475203791633248 | D loss (fake) :  0.01070374809205532
 Epoch  0 Step 200 | G loss : 0.08921218663454056 | D loss (real) :  0.0012647639960050583 | D loss (fake) :  0.0010610106401145458
 Epoch  0 Step 300 | G loss : 0.1312475949525833 | D loss (real) :  0.0045092348009347916 | D loss (fake) :  0.00013347886851988733
 Epoch  0 Step 400 | G loss : 0.09489113092422485 | D loss (real) :  0.007028508000075817 | D loss (fake) :  0.0014972849749028683
 Epoch  0 Step 500 | G loss : 0.09429706633090973 | D loss (real) :  0.0004556688654702157 | D loss (fake) :  0.010345589369535446
 Epoch  0 Step 600 | G loss : 0.01966245099902153 | D loss (real) :  0.02881157211959362 | D loss (fake) :  0.00033998664002865553
 Epoch  1 Step 100 | G loss : 0.09168882668018341 | D loss (real) :  0.005431462544947863 | D loss (fake) :  0.0012483291793614626
 Epoch  1 Step 200 | G loss : 0.07052922993898392 | D loss (real) :  0.0021478375419974327 | D loss (fake) :  0.0007565306732431054
 Epoch  1 Step 300 | G loss : 0.08798977732658386 | D loss (real) :  0.003105106996372342 | D loss (fake) :  0.006881215609610081
 Epoch  1 Step 400 | G loss : 0.08958348631858826 | D loss (real) :  0.0006580824265256524 | D loss (fake) :  0.004958325065672398
 Epoch  1 Step 500 | G loss : 0.097394198179245 | D loss (real) :  0.0011574090458452702 | D loss (fake) :  0.0020227422937750816
 Epoch  1 Step 600 | G loss : 0.06577614694833755 | D loss (real) :  0.0035687191411852837 | D loss (fake) :  0.0016413385747000575
 Epoch  2 Step 100 | G loss : 0.17124325037002563 | D loss (real) :  0.046096112579107285 | D loss (fake) :  2.0071879589522723e-06
 Epoch  2 Step 200 | G loss : 0.09757237136363983 | D loss (real) :  0.0007764383917674422 | D loss (fake) :  0.0031446251086890697
 Epoch  2 Step 300 | G loss : 0.07447242736816406 | D loss (real) :  0.004671276547014713 | D loss (fake) :  0.0019971702713519335
 Epoch  2 Step 400 | G loss : 0.09565374255180359 | D loss (real) :  0.002353147603571415 | D loss (fake) :  0.003264795523136854
 Epoch  2 Step 500 | G loss : 0.0781877413392067 | D loss (real) :  0.00046967656817287207 | D loss (fake) :  0.006120859645307064
 Epoch  2 Step 600 | G loss : 0.06808260083198547 | D loss (real) :  0.0014336074236780405 | D loss (fake) :  0.0018763401312753558
 Epoch  3 Step 100 | G loss : 0.09349960088729858 | D loss (real) :  0.008690927177667618 | D loss (fake) :  0.00012044106551911682
 Epoch  3 Step 200 | G loss : 0.07130831480026245 | D loss (real) :  0.02201704867184162 | D loss (fake) :  6.427030893974006e-05
 Epoch  3 Step 300 | G loss : 0.08110278099775314 | D loss (real) :  0.00043207540875300765 | D loss (fake) :  0.0021495360415428877
 Epoch  3 Step 400 | G loss : 0.1430947482585907 | D loss (real) :  0.0014080422697588801 | D loss (fake) :  0.008117269724607468
 Epoch  3 Step 500 | G loss : 0.10038558393716812 | D loss (real) :  0.0035185415763407946 | D loss (fake) :  0.00319699477404356
 Epoch  3 Step 600 | G loss : 0.09702718257904053 | D loss (real) :  0.0019582367967814207 | D loss (fake) :  0.0016434791032224894
 Epoch  4 Step 100 | G loss : 0.09760792553424835 | D loss (real) :  0.023176025599241257 | D loss (fake) :  0.00012078174768248573
 Epoch  4 Step 200 | G loss : 0.04731793701648712 | D loss (real) :  0.016483111307024956 | D loss (fake) :  0.0006366857560351491
 Epoch  4 Step 300 | G loss : 0.10554307699203491 | D loss (real) :  0.003854199545457959 | D loss (fake) :  0.0002906529698520899
 Epoch  4 Step 400 | G loss : 0.09806756675243378 | D loss (real) :  0.0019741463474929333 | D loss (fake) :  0.0017905696295201778
 Epoch  4 Step 500 | G loss : 0.14819426834583282 | D loss (real) :  0.0011493130587041378 | D loss (fake) :  0.0066104428842663765
 Epoch  4 Step 600 | G loss : 0.06881790608167648 | D loss (real) :  0.0009095235727727413 | D loss (fake) :  0.001093376660719514
 Epoch  5 Step 100 | G loss : 0.1692444533109665 | D loss (real) :  0.00017493240011390299 | D loss (fake) :  0.006499174516648054
 Epoch  5 Step 200 | G loss : 0.09375390410423279 | D loss (real) :  0.0017486498691141605 | D loss (fake) :  0.003918438218533993
 Epoch  5 Step 300 | G loss : 0.09505638480186462 | D loss (real) :  0.001947980490513146 | D loss (fake) :  0.0005991340731270611
 Epoch  5 Step 400 | G loss : 0.09216198325157166 | D loss (real) :  0.0017664358019828796 | D loss (fake) :  0.0004120641970075667
 Epoch  5 Step 500 | G loss : 0.13175278902053833 | D loss (real) :  0.0018861438147723675 | D loss (fake) :  0.00023145071463659406
 Epoch  5 Step 600 | G loss : 0.06416445225477219 | D loss (real) :  3.222330633434467e-05 | D loss (fake) :  0.0015672061126679182
 Epoch  6 Step 100 | G loss : 0.12098735570907593 | D loss (real) :  0.0016466535162180662 | D loss (fake) :  0.0018285703845322132
 Epoch  6 Step 200 | G loss : 0.11837167292833328 | D loss (real) :  0.0005652116960845888 | D loss (fake) :  0.00462131854146719
 Epoch  6 Step 300 | G loss : 0.10575307905673981 | D loss (real) :  0.002826619427651167 | D loss (fake) :  0.0026316174771636724
 Epoch  6 Step 400 | G loss : 0.17353039979934692 | D loss (real) :  0.0006026929477229714 | D loss (fake) :  0.011586824432015419
 Epoch  6 Step 500 | G loss : 0.08456078171730042 | D loss (real) :  0.0025668470188975334 | D loss (fake) :  0.0007258208352141082
 Epoch  6 Step 600 | G loss : 0.07812491804361343 | D loss (real) :  0.0025250976905226707 | D loss (fake) :  0.0007100140210241079
 Epoch  7 Step 100 | G loss : 0.12126940488815308 | D loss (real) :  0.0011537633836269379 | D loss (fake) :  0.0058326879516243935
 Epoch  7 Step 200 | G loss : 0.08854096382856369 | D loss (real) :  0.0022097488399595022 | D loss (fake) :  0.0012135239085182548
 Epoch  7 Step 300 | G loss : 0.07051459699869156 | D loss (real) :  0.008524490520358086 | D loss (fake) :  9.60123143158853e-05
 Epoch  7 Step 400 | G loss : 0.08281420171260834 | D loss (real) :  0.001729589537717402 | D loss (fake) :  0.0006453797104768455
 Epoch  7 Step 500 | G loss : 0.11237454414367676 | D loss (real) :  0.003457212820649147 | D loss (fake) :  0.003991039469838142
 Epoch  7 Step 600 | G loss : 0.08988284319639206 | D loss (real) :  0.0010987174464389682 | D loss (fake) :  0.004595229402184486
 Epoch  8 Step 100 | G loss : 0.1035727858543396 | D loss (real) :  0.00014266843209043145 | D loss (fake) :  0.0028354546520859003
 Epoch  8 Step 200 | G loss : 0.1347159445285797 | D loss (real) :  0.0006534418789669871 | D loss (fake) :  0.015086399391293526
 Epoch  8 Step 300 | G loss : 0.08139529824256897 | D loss (real) :  0.0014790226705372334 | D loss (fake) :  0.003294518683105707
 Epoch  8 Step 400 | G loss : 0.07964469492435455 | D loss (real) :  0.0028928546234965324 | D loss (fake) :  0.002240391680970788
 Epoch  8 Step 500 | G loss : 0.06866402924060822 | D loss (real) :  0.008331898599863052 | D loss (fake) :  0.000922983163036406
 Epoch  8 Step 600 | G loss : 0.11874754726886749 | D loss (real) :  0.0010310696670785546 | D loss (fake) :  0.009447809308767319
