        
ID: test 
 infomation: test beta value for Adam 
 Generator: g_tutorial 
 Discriminator: d_tutorial 
 Learning rate: 0.002 
 Epoch number: 10 
 Batch size: 64 
 =======================

Generator(
  (model): Sequential(
    (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace)
    (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace)
    (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace)
    (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): ReLU(inplace)
    (12): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (13): Tanh()
  )
)
Discriminator(
  (model): Sequential(
    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): LeakyReLU(negative_slope=0.2, inplace)
    (3): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): LeakyReLU(negative_slope=0.2, inplace)
    (6): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): LeakyReLU(negative_slope=0.2, inplace)
    (9): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (10): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): LeakyReLU(negative_slope=0.2, inplace)
    (12): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)
    (13): Sigmoid()
  )
)
 Epoch  0 Step 100 | G loss : 0.017440252006053925 | D loss (real) :  0.010385426692664623 | D loss (fake) :  0.007301384583115578
 Epoch  0 Step 200 | G loss : 0.03152979165315628 | D loss (real) :  0.008751507848501205 | D loss (fake) :  0.009004821069538593
 Epoch  0 Step 300 | G loss : 0.021413937211036682 | D loss (real) :  0.009666306897997856 | D loss (fake) :  0.012446011416614056
 Epoch  0 Step 400 | G loss : 0.033282823860645294 | D loss (real) :  0.0055489810183644295 | D loss (fake) :  0.01924208365380764
 Epoch  0 Step 500 | G loss : 0.048227377235889435 | D loss (real) :  0.0037101043853908777 | D loss (fake) :  0.017970681190490723
 Epoch  0 Step 600 | G loss : 0.0184513870626688 | D loss (real) :  0.015258604660630226 | D loss (fake) :  0.0046755303628742695
 Epoch  1 Step 100 | G loss : 0.017493121325969696 | D loss (real) :  0.017285604029893875 | D loss (fake) :  0.004919900558888912
 Epoch  1 Step 200 | G loss : 0.026709817349910736 | D loss (real) :  0.00914448220282793 | D loss (fake) :  0.010852187871932983
 Epoch  1 Step 300 | G loss : 0.02102776989340782 | D loss (real) :  0.00863562896847725 | D loss (fake) :  0.008861478418111801
 Epoch  1 Step 400 | G loss : 0.02038087695837021 | D loss (real) :  0.012884505093097687 | D loss (fake) :  0.004600975662469864
 Epoch  1 Step 500 | G loss : 0.03234891965985298 | D loss (real) :  0.00885202270001173 | D loss (fake) :  0.0104697709903121
 Epoch  1 Step 600 | G loss : 0.03856060281395912 | D loss (real) :  0.006062740925699472 | D loss (fake) :  0.014334244653582573
 Epoch  2 Step 100 | G loss : 0.050389520823955536 | D loss (real) :  0.0037101234775036573 | D loss (fake) :  0.017549052834510803
 Epoch  2 Step 200 | G loss : 0.01987653411924839 | D loss (real) :  0.009242052212357521 | D loss (fake) :  0.007550712209194899
 Epoch  2 Step 300 | G loss : 0.02178661897778511 | D loss (real) :  0.014344608411192894 | D loss (fake) :  0.0064069717191159725
 Epoch  2 Step 400 | G loss : 0.04291746765375137 | D loss (real) :  0.00396602600812912 | D loss (fake) :  0.017684146761894226
 Epoch  2 Step 500 | G loss : 0.038488104939460754 | D loss (real) :  0.0056410725228488445 | D loss (fake) :  0.013692876324057579
 Epoch  2 Step 600 | G loss : 0.030696578323841095 | D loss (real) :  0.00823083147406578 | D loss (fake) :  0.0114884153008461
 Epoch  3 Step 100 | G loss : 0.02902056649327278 | D loss (real) :  0.008060001768171787 | D loss (fake) :  0.008590864017605782
 Epoch  3 Step 200 | G loss : 0.04587266966700554 | D loss (real) :  0.004462328273802996 | D loss (fake) :  0.014386660419404507
 Epoch  3 Step 300 | G loss : 0.03326793015003204 | D loss (real) :  0.006232018582522869 | D loss (fake) :  0.012894083745777607
 Epoch  3 Step 400 | G loss : 0.03415820747613907 | D loss (real) :  0.006482438649982214 | D loss (fake) :  0.010602695867419243
 Epoch  3 Step 500 | G loss : 0.045937780290842056 | D loss (real) :  0.004785000346601009 | D loss (fake) :  0.01848835125565529
 Epoch  3 Step 600 | G loss : 0.028534550219774246 | D loss (real) :  0.00962348934262991 | D loss (fake) :  0.009476842358708382
 Epoch  4 Step 100 | G loss : 0.020089194178581238 | D loss (real) :  0.011431526392698288 | D loss (fake) :  0.004957276862114668
 Epoch  4 Step 200 | G loss : 0.02728630229830742 | D loss (real) :  0.008308091200888157 | D loss (fake) :  0.007018317934125662
 Epoch  4 Step 300 | G loss : 0.017192240804433823 | D loss (real) :  0.011942539364099503 | D loss (fake) :  0.006145440973341465
 Epoch  4 Step 400 | G loss : 0.03344859927892685 | D loss (real) :  0.008076268248260021 | D loss (fake) :  0.007067692931741476
 Epoch  4 Step 500 | G loss : 0.036233626306056976 | D loss (real) :  0.005985751748085022 | D loss (fake) :  0.01310383528470993
 Epoch  4 Step 600 | G loss : 0.04026518017053604 | D loss (real) :  0.004918117541819811 | D loss (fake) :  0.011444329284131527
 Epoch  5 Step 100 | G loss : 0.02643139660358429 | D loss (real) :  0.010015901178121567 | D loss (fake) :  0.005953778047114611
 Epoch  5 Step 200 | G loss : 0.059813305735588074 | D loss (real) :  0.0047182743437588215 | D loss (fake) :  0.010686629451811314
 Epoch  5 Step 300 | G loss : 0.05551515519618988 | D loss (real) :  0.0029617727268487215 | D loss (fake) :  0.010181499645113945
 Epoch  5 Step 400 | G loss : 0.015139809809625149 | D loss (real) :  0.014983932487666607 | D loss (fake) :  0.0033810287714004517
 Epoch  5 Step 500 | G loss : 0.04798530042171478 | D loss (real) :  0.0036343522369861603 | D loss (fake) :  0.013135682791471481
 Epoch  5 Step 600 | G loss : 0.00913351308554411 | D loss (real) :  0.039147377014160156 | D loss (fake) :  0.0005834726616740227
 Epoch  6 Step 100 | G loss : 0.025482015684247017 | D loss (real) :  0.010149754583835602 | D loss (fake) :  0.0034887343645095825
 Epoch  6 Step 200 | G loss : 0.06104870140552521 | D loss (real) :  0.003094898536801338 | D loss (fake) :  0.016300402581691742
