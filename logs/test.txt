        
ID: test 
 infomation: test beta value for Adam 
 Generator: g_tutorial 
 Discriminator: d_tutorial 
 Learning rate: 0.002 
 Epoch number: 10 
 Batch size: 64 
 =======================

Generator(
  (model): Sequential(
    (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace)
    (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace)
    (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace)
    (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): ReLU(inplace)
    (12): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (13): Tanh()
  )
)
Discriminator(
  (model): Sequential(
    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): LeakyReLU(negative_slope=0.2, inplace)
    (3): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): LeakyReLU(negative_slope=0.2, inplace)
    (6): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): LeakyReLU(negative_slope=0.2, inplace)
    (9): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (10): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): LeakyReLU(negative_slope=0.2, inplace)
    (12): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)
    (13): Sigmoid()
  )
)
 Epoch  0 Step 100 | G loss : 0.08477288484573364 | D loss (real) :  0.00022801748127676547 | D loss (fake) :  0.12175783514976501
 Epoch  0 Step 200 | G loss : 0.02567964419722557 | D loss (real) :  0.007708307355642319 | D loss (fake) :  0.006607384420931339
 Epoch  0 Step 300 | G loss : 0.05128668621182442 | D loss (real) :  0.0072385892271995544 | D loss (fake) :  0.007402142509818077
 Epoch  0 Step 400 | G loss : 0.0651843324303627 | D loss (real) :  0.0035197206307202578 | D loss (fake) :  0.006645509973168373
 Epoch  0 Step 500 | G loss : 0.05082418769598007 | D loss (real) :  0.007585075683891773 | D loss (fake) :  0.006673051975667477
 Epoch  0 Step 600 | G loss : 0.08860915899276733 | D loss (real) :  0.0025339641142636538 | D loss (fake) :  0.014500519260764122
 Epoch  1 Step 100 | G loss : 0.053131893277168274 | D loss (real) :  0.012377011589705944 | D loss (fake) :  0.0005866451538167894
 Epoch  1 Step 200 | G loss : 0.08940726518630981 | D loss (real) :  0.0027007549069821835 | D loss (fake) :  0.010996636003255844
 Epoch  1 Step 300 | G loss : 0.0995221734046936 | D loss (real) :  0.0019532847218215466 | D loss (fake) :  0.012501979246735573
