        
ID: test 
 infomation: test beta value for Adam 
 Generator: g_tutorial 
 Discriminator: d_tutorial 
 Learning rate: 0.002 
 Epoch number: 10 
 Batch size: 64 
 =======================

Generator(
  (model): Sequential(
    (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace)
    (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace)
    (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace)
    (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): ReLU(inplace)
    (12): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (13): Tanh()
  )
)
Discriminator(
  (model): Sequential(
    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): LeakyReLU(negative_slope=0.2, inplace)
    (3): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): LeakyReLU(negative_slope=0.2, inplace)
    (6): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): LeakyReLU(negative_slope=0.2, inplace)
    (9): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (10): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): LeakyReLU(negative_slope=0.2, inplace)
    (12): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)
    (13): Sigmoid()
  )
)
 Epoch  0 Step 100 | G loss : 0.08377602696418762 | D loss (real) :  0.0025348353665322065 | D loss (fake) :  0.0011656247079372406
 Epoch  0 Step 200 | G loss : 0.15438568592071533 | D loss (real) :  0.0014023410622030497 | D loss (fake) :  0.001162824803031981
 Epoch  0 Step 300 | G loss : 0.13565173745155334 | D loss (real) :  0.00019493803847581148 | D loss (fake) :  0.0005168274510651827
 Epoch  0 Step 400 | G loss : 0.07447806745767593 | D loss (real) :  0.003983134403824806 | D loss (fake) :  0.0028005028143525124
 Epoch  0 Step 500 | G loss : 0.11527813225984573 | D loss (real) :  8.716089359950274e-05 | D loss (fake) :  0.0003217414196114987
 Epoch  0 Step 600 | G loss : 0.11485961079597473 | D loss (real) :  0.00015904527390375733 | D loss (fake) :  0.0001018390612443909
 Epoch  1 Step 100 | G loss : 0.1578540951013565 | D loss (real) :  0.0038522151298820972 | D loss (fake) :  0.000381678604753688
 Epoch  1 Step 200 | G loss : 0.11050942540168762 | D loss (real) :  0.001438208157196641 | D loss (fake) :  0.0002510190533939749
 Epoch  1 Step 300 | G loss : 0.22235628962516785 | D loss (real) :  0.0007711889338679612 | D loss (fake) :  0.015717264264822006
 Epoch  1 Step 400 | G loss : 0.07252420485019684 | D loss (real) :  0.0020341582130640745 | D loss (fake) :  7.528987771365792e-05
 Epoch  1 Step 500 | G loss : 0.10075362026691437 | D loss (real) :  0.002127834828570485 | D loss (fake) :  0.0008970728376880288
 Epoch  1 Step 600 | G loss : 0.14790864288806915 | D loss (real) :  0.0021444354206323624 | D loss (fake) :  0.003468138398602605
 Epoch  2 Step 100 | G loss : 0.11761361360549927 | D loss (real) :  0.00047998689115047455 | D loss (fake) :  0.001450168900191784
